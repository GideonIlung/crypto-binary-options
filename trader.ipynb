{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticModel:\n",
    "\n",
    "    def __init__(self,multiclass):\n",
    "\n",
    "        \"\"\"\n",
    "            intialises the Logistic model class\n",
    "\n",
    "            Inputs:\n",
    "                multiclass: specifics if model is a binary classifier or not\n",
    "        \"\"\"\n",
    "\n",
    "        self.W = None\n",
    "        self.multiclass = multiclass\n",
    "\n",
    "    \n",
    "    def predict(self,data,percentage):\n",
    "        \"\"\"\n",
    "            Makes prediction on X dataset\n",
    "        \"\"\"\n",
    "\n",
    "        sigmoid = lambda z: 1/(1+np.exp(-z))\n",
    "\n",
    "        m,n = data.shape\n",
    "        X = np.ones((m,1))\n",
    "        X = np.append(X,data,axis=1)\n",
    "\n",
    "        if self.multiclass == True:\n",
    "\n",
    "            ans = []\n",
    "\n",
    "            output = X @ self.W.T\n",
    "\n",
    "            m,n = output.shape\n",
    "\n",
    "            for i in range(0,m,1):\n",
    "                \n",
    "                temp = output[i,:]\n",
    "                index = np.argmax(temp) + 1\n",
    "                ans.append(index)\n",
    "\n",
    "            return np.array(ans)\n",
    "\n",
    "\n",
    "        elif self.multiclass == False and percentage == True:\n",
    "            return sigmoid(self.W @ X.T)\n",
    "        else:\n",
    "            return np.round(sigmoid(self.W @ X.T)).flatten()\n",
    "\n",
    "\n",
    "    def train(self,data,y,alpha,tol,L,num_iter,seed):\n",
    "\n",
    "        \"\"\"\n",
    "        computes theta Matrix using the logistic Regression\n",
    "        \n",
    "        inputs:\n",
    "            X        : data in the form of the design matrix\n",
    "            y        : the labels associated with the data\n",
    "            alpha    : the learning rate\n",
    "            tol      : the margin of error\n",
    "            num_iter : the number of times algorithms must loop\n",
    "            L        : the regularisation parameter(lambda)\n",
    "        \"\"\"\n",
    "\n",
    "        m,n = data.shape\n",
    "\n",
    "        if(seed == True):\n",
    "            np.random.seed(101)\n",
    "            Theta0 = np.random.randn(1,n+1)\n",
    "\n",
    "        else:\n",
    "            Theta0 = np.random.randn(1,n+1)\n",
    "        \n",
    "        X = np.ones((m,1))\n",
    "        X = np.append(X,data,axis=1)\n",
    "\n",
    "\n",
    "\n",
    "        if(self.multiclass == True):\n",
    "            self.W = self.One_vs_all(X,y,Theta0,alpha,tol,L,num_iter)\n",
    "        else:\n",
    "            self.W = self.LogisticRegression(X,y,Theta0,alpha,tol,L,num_iter)\n",
    "            \n",
    "\n",
    "    def LogisticRegression(self,X,y,theta0,alpha,tol,L,num_iter):\n",
    "        \"\"\"\n",
    "            computes theta values using the psuedo inverse\n",
    "            \n",
    "            inputs:\n",
    "                X        : data in the form of the design matrix\n",
    "                y        : the labels associated with the data\n",
    "                theta0   : the intial guess on the learning parameters\n",
    "                alpha    : the learning rate\n",
    "                tol      : the margin of error\n",
    "                num_iter : the number of times algorithms must loop\n",
    "                L        : the regularisation parameter(lambda)\n",
    "                \n",
    "            outputs:\n",
    "                theta    : the learning parameters given the model\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        sigmoid = lambda z: 1/(1+np.exp(-z))\n",
    "        \n",
    "        i = 1\n",
    "        V = np.copy(theta0)\n",
    "        V[0] = 0\n",
    "        theta_new  = theta0 - alpha*(sigmoid(theta0 @ X.T) - y) @ X + L*V\n",
    "        \n",
    "        while np.linalg.norm(theta_new-theta0) >tol and i <=num_iter:\n",
    "            i+=1\n",
    "            theta0 = theta_new\n",
    "            V = np.copy(theta0)\n",
    "            V[0] = 0\n",
    "            theta_new  = theta0 - alpha*(sigmoid(theta0 @ X.T) - y) @ X + L*V\n",
    "        \n",
    "        return theta_new\n",
    "\n",
    "\n",
    "    def One_vs_all(self,X,y,Theta0,alpha,tol,L,num_iter):\n",
    "\n",
    "        \"\"\"\n",
    "        computes theta Matrix using the logistic Regression\n",
    "        \n",
    "        inputs:\n",
    "            X        : data in the form of the design matrix\n",
    "            y        : the labels associated with the data\n",
    "            theta0   : the intial guess on the learning parameters\n",
    "            alpha    : the learning rate\n",
    "            tol      : the margin of error\n",
    "            num_iter : the number of times algorithms must loop\n",
    "            L        : the regularisation parameter(lambda)\n",
    "            \n",
    "        outputs:\n",
    "            theta    : the learning parameters given the model\n",
    "        \"\"\"\n",
    "    \n",
    "        outcomes = np.unique(y)\n",
    "        Param = []\n",
    "    \n",
    "        for i in range(len(outcomes)):\n",
    "        \n",
    "            value = outcomes[i]\n",
    "            y_sub = self.y_subset(y,value)\n",
    "            temp_theta = Theta0[i,:]\n",
    "            temp_param = self.LogisticRegression(X,y_sub,temp_theta,alpha,tol,L,num_iter)\n",
    "            Param.append(temp_param)\n",
    "        \n",
    "        return np.array(Param)\n",
    "\n",
    "\n",
    "\n",
    "    def y_subset(self,y,value):\n",
    "    \n",
    "        \"\"\"\n",
    "            creates the sub labels for that specific label to train multiclass logistic regression\n",
    "            \n",
    "            inputs:\n",
    "                y        : the true labels associated with the data\n",
    "                value    : the label that will be used to generate the y_subset\n",
    "            \n",
    "            outputs:\n",
    "                y_subset : the labels that will be used to train the logistic regression \n",
    "        \"\"\"\n",
    "        \n",
    "        ans = []\n",
    "        \n",
    "        for i in range(0,len(y),1):\n",
    "            \n",
    "            if(y[i]==value):\n",
    "                ans.append(1)\n",
    "            else:\n",
    "                ans.append(0)\n",
    "        return ans\n",
    "\n",
    "    def confusion_matrix(self,output,y):\n",
    "        \"\"\"\n",
    "            prints out the confusion matrix information\n",
    "\n",
    "            Inputs:\n",
    "                outputs : the predicted outcome of the model\n",
    "                y       : the true label of the data\n",
    "        \"\"\"\n",
    "        outcomes = list(np.unique(y))\n",
    "        \n",
    "        matrix = np.zeros((len(outcomes),len(outcomes)))\n",
    "        \n",
    "        for i in range(0,len(y),1):\n",
    "            \n",
    "            predicted_value = output[i]\n",
    "            true_value = y[i]\n",
    "            \n",
    "            row = outcomes.index(predicted_value)\n",
    "            col = outcomes.index(true_value)\n",
    "            \n",
    "            matrix[row,col] += 1\n",
    "            \n",
    "        \n",
    "        accurary = 0\n",
    "        \n",
    "        for i in range(0,len(outcomes),1):\n",
    "            accurary+= matrix[i][i]\n",
    "            \n",
    "        accurary/= len(y)\n",
    "        f_alarm = matrix[1][0]/(matrix[1][0]+matrix[1][1])\n",
    "        miss = matrix[0][1]/(matrix[0][0]+matrix[0][1])\n",
    "        recall = 1-miss\n",
    "        precision = matrix[0][0]/(matrix[0][0]+matrix[1][0])\n",
    "        con_matrix = pd.DataFrame(data = matrix,index= outcomes,columns=outcomes)\n",
    "\n",
    "        print('\\n============================================================================\\n')\n",
    "        print('accurary :',accurary)\n",
    "        # print('\\n')\n",
    "        print('error :',1-accurary)\n",
    "        # print('\\n')\n",
    "        # print('false alarm :',f_alarm)\n",
    "        # print('\\n')\n",
    "        # print('miss :',miss)\n",
    "        # print('\\n')\n",
    "        # print('recall :',recall)\n",
    "        # print('\\n')\n",
    "        # print('precision :',precision)\n",
    "        # print('\\n')\n",
    "        print('confusion matrix : \\n')\n",
    "        print(con_matrix)\n",
    "        print('\\n============================================================================\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Bitcoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning data#\n",
    "data = pd.read_csv('data/coin_Bitcoin.csv')\n",
    "data = data.drop(['SNo','Name','Symbol','Date'],axis=1)\n",
    "data['change'] = np.nan\n",
    "#data['Date'] = pd.to_datetime(data['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the change in value#\n",
    "n = data.shape[0]\n",
    "\n",
    "for i in range(0,n-1,1):\n",
    "    diff = data['Marketcap'].iloc[i+1] - data['Marketcap'].iloc[i]\n",
    "\n",
    "    if diff >=0:\n",
    "        data['change'].iloc[i] = 1\n",
    "    else:\n",
    "        data['change'].iloc[i] = 0\n",
    "\n",
    "data = data.iloc[0:n-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "train,validate,test = np.split(data.sample(frac=1,random_state=42),[int(0.7*len(data)),int(0.9*len(data))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training#\n",
    "y_train = train['change'].to_numpy()\n",
    "X_train = train.iloc[:,0:-1].to_numpy()\n",
    "\n",
    "#testing#\n",
    "y_test = test['change'].to_numpy()\n",
    "X_test = test.iloc[:,0:-1].to_numpy()\n",
    "\n",
    "#validation#\n",
    "y_validate = validate['change'].to_numpy()\n",
    "X_validate = validate.iloc[:,0:-1].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-2a600a65baa6>:102: RuntimeWarning: overflow encountered in exp\n",
      "  sigmoid = lambda z: 1/(1+np.exp(-z))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================================\n",
      "\n",
      "accurary : 0.5504061156235069\n",
      "error : 0.44959388437649306\n",
      "confusion matrix : \n",
      "\n",
      "       0.0     1.0\n",
      "0.0    0.0     0.0\n",
      "1.0  941.0  1152.0\n",
      "\n",
      "============================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-2a600a65baa6>:205: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  miss = matrix[0][1]/(matrix[0][0]+matrix[0][1])\n"
     ]
    }
   ],
   "source": [
    "model = LogisticModel(multiclass=False)\n",
    "model.train(X_train,y_train,alpha=0.0003,tol=0.03,L=0,num_iter=1000,seed = False)\n",
    "output = model.predict(X_train,percentage = False)\n",
    "model.confusion_matrix(output,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================================\n",
      "\n",
      "accurary : 0.5652173913043478\n",
      "error : 0.4347826086956522\n",
      "confusion matrix : \n",
      "\n",
      "       0.0    1.0\n",
      "0.0    0.0    0.0\n",
      "1.0  130.0  169.0\n",
      "\n",
      "============================================================================\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-2a600a65baa6>:205: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  miss = matrix[0][1]/(matrix[0][0]+matrix[0][1])\n"
     ]
    }
   ],
   "source": [
    "output = model.predict(X_test,percentage=False)\n",
    "model.confusion_matrix(output,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
